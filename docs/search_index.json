[
["index.html", "R Spatial Workshop Notes Fall Quarter 2019 Introduction Workshop Organization Prior Knowledge Topics Additional information", " R Spatial Workshop Notes Fall Quarter 2019 Angela Li Introduction This site contains workshop notes from the R Spatial Workshop at the Center for Spatial Data Science. Workshops are held on Tuesdays from noon-1pm during Fall Quarter 2019. Our goal for running these workshops are to teach researchers how to work effectively with spatial data in R. This workshop mirrors the Introduction to Spatial Data Science course taught by Luc Anselin and Marynia Kolak. You are welcome to join us in Searle 240A for workshops if you’re a member of the UChicago campus community! Bring a laptop to follow along. Workshop Organization Each chapter of this bookdown book represents a 1-hour workshop taught at the center. Chapters will be uploaded after the workshop so you can self study the material. A tentative workshop schedule can be found at this link. Scripts from the workshops will be uploaded to Github following each workshop and can be found at this link. Data used in the workshops will be linked to in each workshop chapter or can be found on the GeoDa Center data website. All data will eventually be found in an R package developed by the CSDS. Prior Knowledge We assume that workshop attendees have used RStudio and are familiar with the basics of R. If you need a refresher, this R for Social Scientists tutorial developed by Data Carpentry is a good place to start. Additionally, Luc Anselin’s introductory R lab notes can be found on the CSDS Tutorials page. Topics We plan to cover the following topics: Spatial data formats Projections Spatial data handling Spatial data operations Static maps Interactive maps Organization of research projects Reproducible research with R Additional information Workshops are run by Angela Li, R Spatial Advocate for the CSDS. If you have any questions about the following material, please reach out to her at ali6@uchicago.edu. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],
["project-setup.html", "Project Setup Prerequisites for Git workflow Workflow with Git Workflow without Git Additional reading", " Project Setup The goal of this section is to help you: Set up a directory on your computer to store scripts and data for this workshop Back up all workshop materials online using Github Prerequisites for Git workflow You have a Github account. If not, create one here. You have Git on your computer. Check by typing git --version in the Terminal pane in RStudio. Macs should already have Git, Windows will need to install Git Bash on their computer. - You have configured Git. Check by typing git config --list in the Terminal pane in RStudio. If you have not configured git, follow these instructions. Workflow with Git Make sure you have the prerequisites for this workflow (see above section), otherwise you’ll be frustrated. Go to github.com and create a new repository. Choose to make it public or private (your choice). Initialize with a README. Open RStudio. Click “New Project”. Click “Version Control”. Paste the URL of the repository you just created. Create the following folders in your project by clicking on “New Folder” in the Files pane in RStudio: data doc R Put data in data, written output in doc, and R code scripts in R. Once you’ve put data and scripts in, you can back up your documents by going to the tab in RStudio called “Git”. Check the checkbox next to the items you’d like to back up. Click “Commit”. Type an informative message, i.e. “Added materials from first workshop”. Click “Push”. You have now uploaded your files to Github. If you go to the web link of the repository you created on Github, your materials should now be there. Workflow without Git Open RStudio. Click “New Project”. Click “New Directory”. Create the following folders in your project by clicking on “New Folder” in the Files pane in RStudio: data doc R Put data in data, written output in doc, and R code scripts in R. Additional reading Happy Git with R: the comprehensive guide on how to use Git/Github with R Project Management with RStudio: great resource for organizing your research files and scripts "],
["introduction-to-spatial-data.html", "Chapter 1 Introduction to Spatial Data 1.1 Learning Objectives 1.2 Spatial Data Basics 1.3 Interactive Tutorial 1.4 Links", " Chapter 1 Introduction to Spatial Data 1.1 Learning Objectives Understand the difference between vector and raster data Describe the components of a PROJ4 string Name the two main packages for spatial vector data in R Import, project, and plot spatial data in R 1.2 Spatial Data Basics We first reviewed some important information about spatial data. The two main types are vector (points, lines, polygons) and raster (pixels, surfaces). Since this workshop is given in the context of social science research, the rest of our workshop focuses on vector data such as administrative boundaries, locations of business, or road networks. Next, we went over what a coordinate reference system was, as well as the components of a PROJ4 string, or how coordinate reference systems are stored electronically. Rather than writing out the whole PROJ4 string, we can use an EPSG code as shorthand for it. This Software Carpentry workshop provides excellent explanations and exercises for understanding coordinate reference systems. Finally, we learned that sf is the modern package for handling spatial data in R. Some old packages still use sp. However, it has a much more complicated representation of spatial data, so we will focus on sf. See this guide for a translation of sp to sf commands, if you’re used to using sp. 1.3 Interactive Tutorial The rest of the workshop was dedicated to a hands-on exercise where we live coded together. The data we used was 1986 Chicago aldermanic ward boundary data, which can be found on the UChicago Map Collection page here. This workshop’s script can be found here. 1.3.1 Functions learned st_read() st_crs() st_transform() 1.3.2 Import spatial data The first thing we’ll do is import the spatial data. Our spatial data happens to be stored as a shapefile (.shp, but actually 4 files). These are getting less fashionable (see GeoJSON, etc.), but a lot of spatial data is still stored this way. First load the sf library. If you don’t have it, install it in your console or in the Packages RStudio pane. # install.packages(&quot;sf&quot;) library(sf) ## Warning: package &#39;sf&#39; was built under R version 3.4.4 ## Linking to GEOS 3.6.1, GDAL 2.1.3, PROJ 4.9.3 We’ll use the st_read function. This also reads GeoJSON, PostGIS databases, and more. ward86 &lt;- st_read(&quot;data/ward1986.shp&quot;) ## Reading layer `ward1986&#39; from data source `/Users/angela/Desktop/Spatial Data Science/workshop-notes/data/ward1986.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 51 features and 1 field (with 1 geometry empty) ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -87.9402 ymin: 41.6443 xmax: -87.524 ymax: 42.0231 ## epsg (SRID): 4269 ## proj4string: +proj=longlat +datum=NAD83 +no_defs You can use the keyboard shortcut Ctrl-Enter to run a line of code in R. Press tab after typing in st_read(&quot;&quot;) with your cursor in between the quotation marks and you’ll get a nice autocomplete feature. Check what projection the data is in: st_crs(ward86) ## Coordinate Reference System: ## EPSG: 4269 ## proj4string: &quot;+proj=longlat +datum=NAD83 +no_defs&quot; Sike, this isn’t projected! You can tell because the proj4string starts with +proj=longlat. You can still plot this, but things will start to get iffy if you try to do distance or area calculations, or plot these ward boundaries with other layers. I can still plot the map, but as a good geographic data analyst, I’ll need to project it. plot(ward86) 1.3.3 Project your data We need to project the data: but how do we choose what projection we need? This is a deep philosophical question, but thankfully the UChicago library has already told us the best projections to use for our data: Illinois East State Plane or UTM Zone 16. I generally do a online search to look up the EPSG codes for the projection I want to use, or use spatialreference.org, which has a database for all EPSG codes for projections. After I do some sleuthing, I find that the EPSG code I want for UTM Zone 16 is 32616. I then use st_transform() to project the data, and save it as a new sf dataframe. ward86_utm &lt;- st_transform(ward86, 32616) I check the CRS - yep, looks right! st_crs(ward86_utm) ## Coordinate Reference System: ## EPSG: 32616 ## proj4string: &quot;+proj=utm +zone=16 +datum=WGS84 +units=m +no_defs&quot; Challenge Question: what datum is this in? What are the units for this projection? Plot it: plot(ward86_utm) Challenge Project the 1986 ward data into the Illinois East State plane projection. Follow the above steps to do so. Hint: look up the EPSG code online! ward86_stateplane &lt;- st_transform(ward86, 3435) st_crs(ward86_stateplane) ## Coordinate Reference System: ## EPSG: 3435 ## proj4string: &quot;+proj=tmerc +lat_0=36.66666666666666 +lon_0=-88.33333333333333 +k=0.9999749999999999 +x_0=300000.0000000001 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=us-ft +no_defs&quot; plot(ward86_stateplane) Note that the +units=us-ft part of the proj4string means that any distance calculations you do on the ward86_stateplane data will be done in feet. Keep in mind that there are “bad” projections for your data. For example, if I accidentally chose the Alaska Albers projection for my data… ward86_alaska &lt;- st_transform(ward86, 3338) plot(ward86_alaska) Clearly this projection isn’t great for Chicago! But something to keep in mind, if, say, you’re making maps of places closer to the poles. ``` 1.4 Links All the links in this workshop: Software Carpentry Vector Data tutorial: https://datacarpentry.org/organization-geospatial/02-intro-vector-data/index.html Software Carpentry CRS tutorial: https://datacarpentry.org/organization-geospatial/03-crs/index.html sf reference site: https://r-spatial.github.io/sf/index.html Migrating from sp to sf guide: https://github.com/r-spatial/sf/wiki/Migrating GeoJSON explanation: http://geojson.org/ Chicago ward data: https://www.lib.uchicago.edu/e/collections/maps/chigis.html Link to good EPSG lookup website: http://spatialreference.org/ "],
["single-dataset-gis-operations.html", "Chapter 2 Single-Dataset GIS Operations 2.1 Learning Objectives 2.2 Functions Learned 2.3 Interactive Tutorial 2.4 Exercises 2.5 Links", " Chapter 2 Single-Dataset GIS Operations 2.1 Learning Objectives Become familiar with several common single-dataset GIS operations Calculate centroids of polygons Create buffers Explore additional single-dataset GIS operations 2.2 Functions Learned st_geometry() st_centroid() st_buffer() st_coordinates() st_bbox() 2.3 Interactive Tutorial This workshop’s script can be found here. 2.4 Exercises Project 1986 ward data into correct UTM projection library(sf) ward86 &lt;- st_read(&quot;data/ward1986.shp&quot;) ## Reading layer `ward1986&#39; from data source `/Users/angela/Desktop/Spatial Data Science/workshop-notes/data/ward1986.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 51 features and 1 field (with 1 geometry empty) ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -87.9402 ymin: 41.6443 xmax: -87.524 ymax: 42.0231 ## epsg (SRID): 4269 ## proj4string: +proj=longlat +datum=NAD83 +no_defs ward86 &lt;- st_transform(ward86, 32616) plot(ward86) Calculate centroids of wards with st_centroid ?st_centroid centroids &lt;- st_centroid(ward86) ## Warning in st_centroid.sf(ward86): st_centroid assumes attributes are ## constant over geometries of x plot(st_geometry(centroids), cex = 0.1) plot(st_geometry(ward86), add = T) plot(st_geometry(ward86)) plot(st_geometry(centroids), cex = 0.1, add = T) Calculate bounding box with st_bbox Plot centroids, buffered centroids, and wards for each year 2.5 Links Geometric unary operations (aka, single dataset operations): https://r-spatial.github.io/sf/reference/geos_unary.html sf cheatsheet: https://github.com/rstudio/cheatsheets/blob/master/sf.pdf PostGIS cheatsheet (off of which sf is based): http://www.postgis.us/downloads/postgis21_cheatsheet.pdf "],
["multiple-dataset-gis-operations-visualization.html", "Chapter 3 Multiple-Dataset GIS Operations / Visualization 3.1 Learning Objectives 3.2 Functions Learned 3.3 Interactive Tutorial 3.4 Links", " Chapter 3 Multiple-Dataset GIS Operations / Visualization 3.1 Learning Objectives Create multi-layered maps Calculate the area of polygons Find spatial intersections 3.2 Functions Learned ggplot() geom_sf() st_intersects() filter(): picks cases based on their values, from the dplyr package. Hint: For each new function we go over, type ? in front of it in the console to pull up the help page. 3.3 Interactive Tutorial This workshop’s script can be found here. Challenge Do you remember how to read in and project data? Try it out! Also calculate the centroids. library(sf) ward98 &lt;- st_read(&quot;data/ward1998.shp&quot;) ## Reading layer `ward1998&#39; from data source `/Users/angela/Desktop/Spatial Data Science/workshop-notes/data/ward1998.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 50 features and 2 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -87.94021 ymin: 41.64434 xmax: -87.52404 ymax: 42.02313 ## epsg (SRID): 4269 ## proj4string: +proj=longlat +datum=NAD83 +no_defs ward98 &lt;- st_transform(ward98, 32616) centroids &lt;- st_centroid(ward98) ## Warning in st_centroid.sf(ward98): st_centroid assumes attributes are ## constant over geometries of x We are going to start plotting with a new package: ggplot2. This is my favorite package for plotting sf objects, as there is a special function in the package called geom_sf that expressly handles spatial data. The syntax of a ggplot call is as follows: To plot an sf object, use geom_sf(). library(ggplot2) ggplot(data = ward98) + geom_sf() Challenge Use geom_sf to make a ggplot of the centroids data. ggplot(data = centroids) + geom_sf() Note: If you keep getting the following error message, try reversing the geom_sfs again and/or highlighting/re-running the lines of code multiple times. Error in grid.Call(C_textBounds, as.graphicsAnnot(x\\(label), x\\)x, x$y, : polygon edge not found One nice thing about ggplot is that it’s super easy to layer things. For example, if I want to plot the wards and the centroids, I can do that by moving the data = argument to within the geom_sf() call. ggplot() + geom_sf(data = ward98) + geom_sf(data = centroids) I can also change colors and other settings. ggplot() + geom_sf(data = ward98, fill = &quot;lightblue&quot;) + geom_sf(data = centroids, color = &quot;blue&quot;) So far, we’ve plotted data that was from the same original dataset. What if we want to add a layer with Chicago’s waterways? First we download, import, and project data from the Chicago Data Portal. As an exercise, I’m going to download a Chicago waterways data GeoJSON, which st_read can also interpret and convert into an sf object. Challenge Read and project the waterways JSON. Hint: save your JSON file in the data/ folder in your workspace. water &lt;- st_read(&quot;data/Waterways.geojson&quot;) ## Reading layer `OGRGeoJSON&#39; from data source `/Users/angela/Desktop/Spatial Data Science/workshop-notes/data/Waterways.geojson&#39; using driver `GeoJSON&#39; ## Simple feature collection with 605 features and 6 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -87.9389 ymin: 41.6195 xmax: -86.20666 ymax: 43.21631 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs water &lt;- st_transform(water, 32616) Now, plot it to see if things are looking alright. ggplot() + geom_sf(data = water) Uh oh, looks like we have Lake Michigan with everything else. We want to filter out that feature. We’ll use the filter() command from dplyr. library(dplyr) water_clean &lt;- filter(water, name != &quot;LAKE MICHIGAN&quot;) Now we can make a map with both the wards and the waterways in Chicago. ggplot() + geom_sf(data = ward98) + geom_sf(data = water_clean, color = &quot;blue&quot;) Note that order matters here! ggplot plots in the order that you give your functions to it, so if you reorder the geom_sf calls, the wards are mapped after - and on top of! - the rivers. # Incorrect order of geom_sf() calls ggplot() + geom_sf(data = water_clean, color = &quot;blue&quot;) + geom_sf(data = ward98) The last thing we’ll do is figure out which wards intersect with waterways, using a powerful sf function called st_intersects. The output of st_intersects is a bit strange: it’s a list of indexes of the intersected features for each ward. The main thing you need to know is: if there is nothing in the list for a feature, that means nothing intersects with it. intersects &lt;- st_intersects(ward98, water_clean) str(intersects) ## List of 50 ## $ : int [1:146] 21 28 38 39 46 47 59 67 68 71 ... ## $ : int [1:28] 2 3 4 5 6 7 8 9 10 11 ... ## $ : int [1:24] 1 2 15 16 17 18 19 20 22 23 ... ## $ : int(0) ## $ : int(0) ## $ : int [1:3] 186 187 189 ## $ : int [1:3] 45 62 63 ## $ : int [1:3] 192 194 195 ## $ : int(0) ## $ : int [1:6] 381 389 390 569 579 586 ## $ : int [1:6] 64 65 66 143 155 156 ## $ : int 224 ## $ : int [1:14] 37 40 43 44 49 50 51 53 54 55 ... ## $ : int(0) ## $ : int 382 ## $ : int [1:34] 2 3 15 16 17 18 19 20 303 569 ... ## $ : int [1:13] 30 314 315 316 328 329 458 463 464 466 ... ## $ : int [1:23] 154 228 297 310 311 321 323 325 327 330 ... ## $ : int [1:6] 370 581 582 583 584 585 ## $ : int [1:3] 380 384 386 ## $ : int 58 ## $ : int(0) ## $ : int(0) ## $ : int [1:21] 291 292 293 294 295 296 307 308 309 311 ... ## $ : int [1:18] 383 400 401 402 411 413 420 422 428 429 ... ## $ : int [1:3] 509 510 511 ## $ : int(0) ## $ : int [1:16] 264 446 447 452 454 455 460 462 465 478 ... ## $ : int(0) ## $ : int 449 ## $ : int [1:34] 168 191 250 255 256 257 267 268 274 275 ... ## $ : int(0) ## $ : int [1:15] 227 247 250 253 258 265 275 280 284 290 ... ## $ : int [1:67] 29 60 61 79 152 153 162 178 193 213 ... ## $ : int [1:59] 70 99 154 228 297 310 331 332 333 334 ... ## $ : int [1:17] 48 241 248 298 299 300 301 302 305 306 ... ## $ : int 469 ## $ : int [1:15] 153 200 251 252 254 260 262 263 266 270 ... ## $ : int [1:2] 425 438 ## $ : int [1:8] 432 433 439 440 453 456 458 459 ## $ : int(0) ## $ : int(0) ## $ : int [1:32] 144 145 146 147 148 149 150 151 157 158 ... ## $ : int [1:4] 205 221 227 526 ## $ : int(0) ## $ : int(0) ## $ : int [1:32] 69 73 87 105 119 121 126 133 135 138 ... ## $ : int [1:7] 80 84 89 229 230 232 236 ## $ : int(0) ## $ : int [1:2] 190 223 ## - attr(*, &quot;predicate&quot;)= chr &quot;intersects&quot; ## - attr(*, &quot;region.id&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## - attr(*, &quot;ncol&quot;)= int 604 ## - attr(*, &quot;class&quot;)= chr &quot;sgbp&quot; Note: This is where projection is extremely important. If you get an error message that says: Error: st_crs(x) == st_crs(y) is not TRUE that probably means that you forgot to project one of your datasets. Check the CRS with both and fix it with st_transform. This is a little hairy, so in order to use this reasonably, we combine it with the filter command we learned earlier. We are filtering the original data by whether or not it has any water features that intersect with it. water_wards &lt;- filter(ward98, lengths(intersects) &gt; 0) Note: Don’t forget the s in lengths like I did during the workshop! Challenge Can you plot the wards, the rivers, and the wards that intersect with a river? The grand finale! ggplot() + geom_sf(data = ward98) + geom_sf(data = water_wards, fill = &quot;lightblue&quot;) + geom_sf(data = water_clean, color = &quot;blue&quot;) Remember to push your work to Github to back it up! 3.4 Links Link to current Chicago waterways data: https://data.cityofchicago.org/Parks-Recreation/Waterways/eg9f-z3t6 geom_sf documentation page: https://ggplot2.tidyverse.org/reference/ggsf.html ggsave documentation page: https://ggplot2.tidyverse.org/reference/ggsave.html dplyr package documentation site: https://dplyr.tidyverse.org Excellent blog post on how to manipulate spatial information: http://strimas.com/r/tidy-sf/ "],
["multiple-dataset-gis-operations-visualization-pt-2.html", "Chapter 4 Multiple-Dataset GIS Operations / Visualization pt. 2 4.1 Learning Objectives 4.2 Functions Learned 4.3 Interactive Tutorial 4.4 Challenges 4.5 Links", " Chapter 4 Multiple-Dataset GIS Operations / Visualization pt. 2 4.1 Learning Objectives Combine two datasets with spatial join Perform spatial aggregation (point in polygon) Manipulate data with dplyr Save a ggplot image 4.2 Functions Learned st_join() select() count() arrange() st_geometry() ggsave() Hint: For each new function we go over, type ? in front of it in the console to pull up the help page. 4.3 Interactive Tutorial This workshop’s script can be found here. 4.4 Challenges We’ve been reading shapefiles that we’ve downloaded, but we call also read data directly from a website using an “API”. These are often great ways to get data without having to manually download it. We’re going to read data from the Chicago Data Portal: Libraries points Community Area polygons Click on the “API” button to directly access the data, rather than having to download a csv via “Export”. Challenge Which one of these is a geographic data format? Challenge Fill in the following script: # Load libraries for use areas &lt;- st_read(&quot;https://data.cityofchicago.org/resource/igwz-8jzy.geojson&quot;) ## Reading layer `OGRGeoJSON&#39; from data source `https://data.cityofchicago.org/resource/igwz-8jzy.geojson&#39; using driver `GeoJSON&#39; ## Simple feature collection with 77 features and 9 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -87.94011 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs # Read in libraries and areas data # Project both # Make a ggplot with libraries and community areas Challenge Which community areas have no libraries? Use st_intersects and filter to make a map. # Load library with filter() in it # Find which areas intersect with libraries and save as a variable called &quot;intersects&quot; # Filter areas by *without* libraries. Save as a variable called &quot;no_lib&quot; Hint: use &quot;==&quot; instead of &quot;&gt;&quot; in the logical comparison # Make a ggplot with libraries, community areas, and community areas without libraries The order in which you give arguments to st_intersects matters! I always have to look it up, but for point-in-polygon, you want the polygon first, then the points. One question you may be asking yourself is, how many libraries are in each area? We can tackle this with an operation known as a spatial join. What we do is join information about the polygons to the points, so we have for each point which community area it’s in. More formally, we are adding the attributes of a layer to the other one. A spatial join is not the same as an attribute join, which is based on common column (attribute) values between two datasets. Spatial joins are based on a spatial relationship: is this point inside this polygon? You can try doing an attribute join on community area number/name with this Public Health dataset, and the command left_join() from dplyr. The syntax is generally as follows, for point-in-polygon: st_join(point_sf, poly_sf) 4.4.1 A simple example We can spatial join just one attribute, or a few. We can use select() to choose attributes. One we’ve done our spatial join, we can manipulate the data with count() and arrange() to figure out which community areas have the most libraries. This is also known as spatial aggregation. If work with the spatial data gets too clumsy or slow, we can drop the geometry column with st_geometry()&lt;-. 4.4.2 Saving your plots We ran out of time for this last time, but to save a ggplot image, you can use ggsave() after a ggplot2 command. You can adjust the width and height of the image in arguments to the function. Challenge Save one of the plots we’ve made in this workshop to figs/name-of-plot.png. 4.5 Links All the links in this workshop: Link to Chicago Libraries data: https://data.cityofchicago.org/Education/Libraries-Locations-Hours-and-Contact-Information/x8fc-8rcq Link to Chicago Community Areas data: https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6 "],
["r-markdown-and-custom-maps.html", "Chapter 5 R Markdown and Custom Maps 5.1 Learning Objectives 5.2 Topics Learned 5.3 Interactive Tutorial 5.4 Challenges 5.5 Links", " Chapter 5 R Markdown and Custom Maps 5.1 Learning Objectives Create a R Markdown document Embed code and text in an R Markdown document Manipulate R Markdown chunk options Become familiar with the tmap package 5.2 Topics Learned .rmd structure Code chunks in R Markdown Note: If you do not have LaTeX installed on your computer, please install tinytex using the following commands so that you will be able to Knit to a PDF and Beamer during this workshop. install.packages(‘tinytex’) tinytex::install_tinytex() Hint: Use the R Markdown guides in RStudio under Help &gt; Cheatsheets &gt; R Markdown Cheatsheet (or R Markdown Reference Guide) for help. 5.3 Interactive Tutorial This workshop’s R Markdown can be found here. 5.4 Challenges We’re going to continue using the data we used last week from the Chicago Data Portal, but we’ll be working in a R Markdown document instead of a R script. Challenge Create a new R Markdown document. Knit the document. Change the YAML header at the top to include your personal information. Try changing some of the options in the header (aka the options between the “—”): output: pdf_document fontsize: 14pt You can use this reference guide to help you out. Challenge Use Markdown formatting to write some information about the Chicago libraries and community areas datasets. Use: sections bold/italic text two types of lists Challenge Insert an ggplot2 image that we created last time in the document. Here’s the data from last week: Libraries points Community Area polygons Remember: you can click on the “API” button to directly access the data, rather than having to download a csv via “Export”. Challenge Add code chunks that: load packages read data create a ggplot2 plot Challenge Add chunk options that: load packages (hide this code) read data (show this code, and run it) create a ggplot2 plot (don’t show this code, but run it, and control the size of the figure) Try naming your chunks something useful. Challenge Try making a map with tmap (similar syntax as ggplot2), using the tmap vignette. Luc Anselin has written a more in-depth tutorial for tmap, which you can find and go through here, under Introduction to Spatial Data Science &gt; Basic Mapping. 5.5 Links All the links in this workshop: Link to Chicago Libraries data: https://data.cityofchicago.org/Parks-Recreation/Waterways/eg9f-z3t6 Link to Chicago Community Areas data: https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6 Link to R Markdown site: https://rmarkdown.rstudio.com Link to Software Carpentry R Markdown tutorial: https://swcarpentry.github.io/r-novice-gapminder/15-knitr-markdown/ Getting started with tmap vignette: https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html Geocomputation with R - good chapter on making maps with tmap: https://geocompr.robinlovelace.net/adv-map.html "],
["custom-and-animated-maps.html", "Chapter 6 Custom and Animated Maps 6.1 Learning Objectives 6.2 Functions Learned 6.3 Interactive Tutorial 6.4 Challenges 6.5 Links", " Chapter 6 Custom and Animated Maps 6.1 Learning Objectives Use urban_agglomerations and world data from the spData package Make the same map in ggplot2 and tmap Make an animated map and save it 6.2 Functions Learned tm_shape tm_polygons tm_dots tm_facets tmap_animation 6.3 Interactive Tutorial This workshop’s R Markdown can be found here. 6.4 Challenges This workshop uses an example from Geocomputation with R, developed by Robin Lovelace. The original script can be found online. If you get the following error, make sure the magick package is installed with install.packages(“magick”), and that ImageMagick itself is installed: Error in tmap::tmap_animation(tm, filename = “doc/city-pop.gif”) : Could not find ImageMagick. Make sure it is installed and included in the systems PATH Challenge Look at the urban_agglomerations and the world data. What type of spatial data is each (point, line, polygon)? How many observations are in each dataset? What projection is each in? Make a ggplot2 map of both datasets Challenge Make a tmap map of urban_agglomerations. Challenge Change the color of the points to one of your choosing. Luc Anselin has written a more in-depth tutorial for tmap, which you can find and go through here, under Introduction to Spatial Data Science &gt; Basic Mapping. 6.5 Links The links in this workshop: Geocomputation with R - Chapter 8 talks about making maps with tmap: https://geocompr.robinlovelace.net/adv-map.html Getting started with tmap vignette: https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html "],
["interactive-maps.html", "Chapter 7 Interactive Maps 7.1 Learning Objectives 7.2 Functions Learned 7.3 Overview 7.4 Interactive Tutorial 7.5 R Training Workshop 7.6 Next week(s?)", " Chapter 7 Interactive Maps 7.1 Learning Objectives Explore the various options in R for interactive mapping in 3 packages: tmap, mapview, and leaflet 7.2 Functions Learned tmap_mode mapview leaflet addProviderTiles addCircles 7.3 Overview This workshop teaches section Chapter 8.4: Interactive Maps of Geocomputation with R. It also digs into the vignettes for mapview, which can be found at the mapview documentation website. 7.4 Interactive Tutorial This workshop’s R Markdown can be found here. 7.5 R Training Workshop I will be teaching a day-long “R for Social Scientists” Data Carpentry workshop on April 12 at the Center for Spatial Data Science. Topics to be covered include: Introduction to R Working with data types, strings, and dates in R Manipulating data frames in R Data visualization in R …and lunch will be provided! Please register at this link if you are interested! 7.6 Next week(s?) What topics do you want me to cover? Fill out this Google Form and I’ll see what I can do! "],
["interactive-maps-with-shiny.html", "Chapter 8 Interactive Maps with Shiny 8.1 Learning Objectives 8.2 Topics Learned 8.3 Overview 8.4 Interactive Tutorial 8.5 R Training Workshop 8.6 Links", " Chapter 8 Interactive Maps with Shiny 8.1 Learning Objectives Create a basic Shiny app using leaflet 8.2 Topics Learned Shiny (UI vs. server) Interactivity Find the Shiny cheatsheet in RStudio under Help &gt; Cheatsheets &gt; Web Applications with shiny 8.3 Overview This workshop teaches how to create a basic Shiny web app using leaflet. 8.4 Interactive Tutorial This workshop’s Shiny app code can be found here. Challenge Create a new Shiny app from a template in R. Run the app. Which parts of the Shiny UI code map to the app? How are ui and server linked (what are the features that are the same across both?) Change the title of the app. Challenge In the UI object, add a leafletOutput(&quot;map&quot;) call in the mainPanel() function. Then, in the server object, add a output$map &lt;- renderLeaflet({}) call. That is, fill in the following script: ui &lt;- fluidPage( # Application title titlePanel(&quot;World Population Over Time&quot;), # Sidebar with a slider input for number of bins sidebarLayout( sidebarPanel( # sliderInput(&quot;bins&quot;, # &quot;Number of bins:&quot;, # min = 1, # max = 50, # value = 30), ), # Specifies what to put in the main panel mainPanel( # Put one line of code here ) ) ) server &lt;- function(input, output) { # output$distPlot &lt;- renderPlot({ # # generate bins based on input$bins from ui.R # x &lt;- faithful[, 2] # bins &lt;- seq(min(x), max(x), length.out = input$bins + 1) # # # draw the histogram with the specified number of bins # hist(x, breaks = bins, col = &#39;darkgray&#39;, border = &#39;white&#39;) # }) output$map &lt;- renderLeaflet({ # Put three lines of leaflet code here }) } Challenge In the UI object, add a sliderInput of &quot;year&quot;. Change the step size to 5, and remove the comma for thousands (hint: do ?sliderInput to look at the documentation, and options). Challenge Create a new variable called pop_per_year that is a subset of city by year, depending on which year you enter (input$year). Use the filter() command in the dplyr package. Challenge Try resizing the marker size depending on population, adding a popup, or doing more to customize your map! Try adding a feature in your app so that you only show cities over a certain population in millions (specified by the user), using numericInput() instead of sliderInput(). Challenge Add a data table element with renderDataTable() and dataTableOutput() so you can see the attributes of the points in the map. You can share your Shiny apps publicly by creating an account at https://shinyapps.io and clicking Publish in the top of your app script. 8.5 R Training Workshop I will be teaching a day-long “R for Social Scientists” Data Carpentry workshop on April 12 at the Center for Spatial Data Science. Topics to be covered include: Introduction to R Working with data types, strings, and dates in R Manipulating data frames in R Data visualization in R …and lunch will be provided! Please register at this link if you are interested! 8.6 Links Leaflet documentation website: https://rstudio.github.io/leaflet/ Intro to Shiny webinar (45 minutes): https://www.rstudio.com/resources/webinars/introduction-to-shiny/ Free Shiny online course from Datacamp: https://www.datacamp.com/courses/building-web-applications-in-r-with-shiny Shiny examples: Generate random points on a map: https://bhaskarvk.github.io/user2017.geodataviz/presentations/07-Interactive_Maps.html#36 Zip code explorer: http://shiny.rstudio.com/gallery/superzip-example.html Twin cities bus dashboard: https://gallery.shinyapps.io/086-bus-dashboard/ "],
["introduction-to-raster-data.html", "Chapter 9 Introduction to Raster Data 9.1 Overview 9.2 Links", " Chapter 9 Introduction to Raster Data 9.1 Overview This workshop introduces raster data and how to work with it in R. We will be working through the first part of the Geospatial Data workshop put together by Data Carpentry. Please download data for this workshop at this link. 9.2 Links Introduction to Raster Data, Data Carpentry (what is it?): https://datacarpentry.org/organization-geospatial/01-intro-raster-data/index.html Working with Raster Data in R, Data Carpentry: https://datacarpentry.org/r-raster-vector-geospatial/01-raster-structure/index.html Data for this workshop: http://datacarpentry.org/geospatial-workshop/data/ Great resource for more tutorials regarding spatial data: https://www.earthdatascience.org "],
["introduction-to-interpolation.html", "Chapter 10 Introduction to Interpolation 10.1 Overview 10.2 Make sure relevant packages are installed 10.3 Links", " Chapter 10 Introduction to Interpolation 10.1 Overview This workshop introduces interpolation in R using an example built into the sp package, measuring lead levels at various points. The built-in dataset is called meuse. 10.2 Make sure relevant packages are installed In order to complete this workshop, you will need the following packages: sp gstat We also recommend the following: ggplot2 tmap sf 10.3 Links gstat meuse vignette: https://cran.r-project.org/web/packages/gstat/vignettes/gstat.pdf Explanation of working with the meuse dataset: https://rpubs.com/nabilabd/118172 "],
["interpolation-with-array-of-things-data.html", "Chapter 11 Interpolation with Array of Things Data 11.1 Overview 11.2 Download data 11.3 Links", " Chapter 11 Interpolation with Array of Things Data 11.1 Overview This workshop continues teaching interpolation in R using Array of Things data. This is based on Part 2 of the Array of Things workshop put together by Marynia Kolak at the CSDS. 11.2 Download data Please download data for this workshop by going to the following link and right-clicking on “Raw”, then saving the link as a CSV on your computer. Or, you can run the following code in your console: download.file(&quot;https://github.com/spatialanalysis/workshop-notes/raw/master/data/node_temps.csv&quot;, destfile = &quot;node-temps.csv&quot;) Also download a copy of the Chicago Community Area data here, or use the API Endpoint (copy and paste into your console). library(sf) areas &lt;- st_read(&quot;https://data.cityofchicago.org/resource/igwz-8jzy.geojson&quot;) ## Reading layer `OGRGeoJSON&#39; from data source `https://data.cityofchicago.org/resource/igwz-8jzy.geojson&#39; using driver `GeoJSON&#39; ## Simple feature collection with 77 features and 9 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -87.94011 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs Challenge Read in the csv as an sf object, then explore it using exploratory data functions like head(), str(), summary(), and plot() Challenge Try making a map of the nodes, with the community areas, using ggplot2. Challenge Convert the sf object into an sp object. Hint: as_Spatial(sf) should do the trick. Challenge Make an empirical variogram of the data. Challenge Krige! Try out a few types of models: spherical, exponential, and linear. 11.3 Links When you can’t find great R documentation of concepts, ArcGIS documentation will do: Semivariogram and covariance functions Alternate explanation of how to interpolate with kriging (also uses proprietary GIS software): Kriging interpolation Variogram tutorial that provides some good, clear explanation of complicated concepts "],
["spatial-data-handling.html", "Chapter 12 Spatial Data Handling 12.1 Learning Objectives 12.2 Functions Learned 12.3 Interactive Tutorial 12.4 Reading data from an open data portal 12.5 Selecting data to work with 12.6 Spatial data time - my favorite part! 12.7 On your own 12.8 Very important concepts: projection, and spatial join", " Chapter 12 Spatial Data Handling 12.1 Learning Objectives Read data from an open data portal Manipulate non-spatial data in R Convert data from lat/lon into a simple features object Project spatial data Join data based on spatial attributes Create a basic choropleth map 12.2 Functions Learned loading packages: library() reading from an API: read.socrata() data exploration: head(), dim(), class(), names(), is.na(), plot() selecting data: filter(), select() creating a spatial object: st_as_sf(), st_crs(), read_sf(), st_geometry() projecting data: st_transform() Hint: For each new function we go over, type ? in front of it in the console to pull up the help page. 12.3 Interactive Tutorial The notebook with a more detailed version of this workshop can be found here. We will not cover everything in Luc’s detailed tutorial, but we will go over basic commands and common gotchas, in order to help you feel comfortable working through the tutorial. Please make sure you have the following packages installed: tidyverse RSocrata sf tmap lubridate You can install all of these at once with the following command: install.packages(c(&quot;tidyverse&quot;, &quot;RSocrata&quot;, &quot;sf&quot;, &quot;tmap&quot;, &quot;lubridate&quot;)) We start by loading the packages we need for this workshop. Here, I’ve loaded the “tidyverse” package with the library() function. library(tidyverse) Challenge Can you load the RSocrata, sf, tmap, and lubridate packages with the same function? 12.4 Reading data from an open data portal We then read data about 311 calls from a URL, otherwise known as an API. This is a straightforward way to quickly get data from an open data portal, without having to download and manage the data file locally. Here’s the data documentation site, from the City of Chicago. This will take a while to run, as we’re pulling over 250,000 observations vehicle_data &lt;- read.socrata(&quot;https://data.cityofchicago.org/resource/suj7-cg3j.csv&quot;) Challenge Try calling the head(), dim(), and class() functions on the new vehicle_data R object. What does the data look like? How many observations and variables are there? 12.5 Selecting data to work with In general, I may only be interested in a subset of the data. I’ll use the filter command to pull out only 311 calls from 2005. That year() function is pulling out the year from the date column (spreadsheet software often has this functionality as well). The %&gt;% is known as the “pipe”, and means “take vehicle_data, and pass it as the first argument to the next function. It comes in handy when I want to perform multiple operations in the”tidyverse&quot;. vehicle_data %&gt;% filter(year(creation_date) == 2005) ## creation_date status completion_date service_request_number ## 1 2005-02-10 Completed 2017-01-11 05-00213608 ## 2 2005-03-30 Completed - Dup 2017-01-11 05-00464206 ## 3 2005-06-16 Completed - Dup 2017-01-11 05-00932280 ## 4 2005-06-16 Completed 2017-01-11 05-00932409 ## 5 2005-06-16 Completed 2017-01-11 05-00933568 ## 6 2005-06-17 Completed - Dup 2017-01-11 05-00941492 ## 7 2005-08-01 Completed - Dup 2017-01-11 05-01221973 ## 8 2005-08-26 Completed - Dup 2017-01-11 05-01396640 ## type_of_service_request license_plate vehicle_make_model ## 1 Abandoned Vehicle Complaint 32L5657 Chrysler ## 2 Abandoned Vehicle Complaint ## 3 Abandoned Vehicle Complaint T159050 Honda ## 4 Abandoned Vehicle Complaint ## 5 Abandoned Vehicle Complaint ## 6 Abandoned Vehicle Complaint Toyota ## 7 Abandoned Vehicle Complaint 5823771 Oldsmobile/Cutlass/Ciera ## 8 Abandoned Vehicle Complaint ## vehicle_color current_activity most_recent_action ## 1 Black FVI - Outcome Create Work Order ## 2 ## 3 Black FVI - Outcome Create Work Order ## 4 FVI - Outcome Create Work Order ## 5 FVI - Outcome Create Work Order ## 6 Blue FVI - Outcome Create Work Order ## 7 Blue ## 8 ## how_many_days_has_the_vehicle_been_reported_as_parked_ ## 1 NA ## 2 NA ## 3 NA ## 4 NA ## 5 NA ## 6 NA ## 7 NA ## 8 NA ## street_address zip_code x_coordinate y_coordinate ward ## 1 1030 S MENARD AVE 60644 NA NA 29 ## 2 917 W EASTWOOD AVE 60640 1169205 1931086 46 ## 3 8905 S BRANDON AVE 60617 1198886 1846522 10 ## 4 9127 S ELLIS AVE 60619 NA NA 8 ## 5 1855 S CLINTON ST 60616 NA NA 25 ## 6 4829 W WOLFRAM ST 60641 1143697 1918515 31 ## 7 2507 W CERMAK RD NA 1160049 1889322 28 ## 8 7321 S PRINCETON AVE 60621 1175560 1856415 6 ## police_district community_area ssa latitude longitude ## 1 15 25 NA 41.86824 -87.76946 ## 2 23 3 34 41.96628 -87.65349 ## 3 4 46 NA 41.73358 -87.54686 ## 4 4 47 NA 41.72860 -87.59964 ## 5 12 31 NA 41.85588 -87.64027 ## 6 25 19 NA 41.93232 -87.74782 ## 7 10 30 NA 41.85190 -87.68826 ## 8 7 69 NA 41.76110 -87.63196 ## location location_address ## 1 POINT (41.86823989759004 -87.76946043478485) &lt;NA&gt; ## 2 POINT (41.96628368822802 -87.65349140566876) &lt;NA&gt; ## 3 POINT (41.73357538693858 -87.5468638464287) &lt;NA&gt; ## 4 POINT (41.72859955416313 -87.59963819790387) &lt;NA&gt; ## 5 POINT (41.85588399821447 -87.64026997646823) &lt;NA&gt; ## 6 POINT (41.93231981463456 -87.74781719104732) &lt;NA&gt; ## 7 POINT (41.85189851760397 -87.6882562971527) &lt;NA&gt; ## 8 POINT (41.76110443455052 -87.63196391292958) &lt;NA&gt; ## location_city location_state location_zip ## 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 8 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; # equivalent to: # filter(vehicle_data, year(creation_data = 2005)) Challenge Filter the data so that you only have observations from September 2016 (how do you filter on multiple criteria at once? Look at the documentation!). Save it to a new dataframe called vehicle_sept16. Check that you’ve done it correctly with head() and dim(). Sometimes, I have more columns in my data than I need. I can choose a few columns, and assign it to a new dataset. First, I get the variable names: names(vehicle_sept16) ## [1] &quot;creation_date&quot; ## [2] &quot;status&quot; ## [3] &quot;completion_date&quot; ## [4] &quot;service_request_number&quot; ## [5] &quot;type_of_service_request&quot; ## [6] &quot;license_plate&quot; ## [7] &quot;vehicle_make_model&quot; ## [8] &quot;vehicle_color&quot; ## [9] &quot;current_activity&quot; ## [10] &quot;most_recent_action&quot; ## [11] &quot;how_many_days_has_the_vehicle_been_reported_as_parked_&quot; ## [12] &quot;street_address&quot; ## [13] &quot;zip_code&quot; ## [14] &quot;x_coordinate&quot; ## [15] &quot;y_coordinate&quot; ## [16] &quot;ward&quot; ## [17] &quot;police_district&quot; ## [18] &quot;community_area&quot; ## [19] &quot;ssa&quot; ## [20] &quot;latitude&quot; ## [21] &quot;longitude&quot; ## [22] &quot;location&quot; ## [23] &quot;location_address&quot; ## [24] &quot;location_city&quot; ## [25] &quot;location_state&quot; ## [26] &quot;location_zip&quot; Then, I extend the code I wrote above: vehicle_final &lt;- vehicle_sept16 %&gt;% select(location_address, zip_code) Or, I can even get rid of the intermediate vehicle_sept16 object! vehicle_final &lt;- vehicle_data %&gt;% filter(year(creation_date) == 2016, month(creation_date) == 9) %&gt;% select(location_address, zip_code) The columns I selected aren’t going to be that useful in terms of performing spatial analysis. Why? Because they’re human understandings of where something is. In order for a computer to understand how to map something. I need something a bit more specific. If that’s all I had, I’d need to geocode my addresses, but thankfully I already have two columns in there with the information I need. Challenge What columns am I interested in? Replace the column names with the proper ones. I can also rename my columns as I select them, for easier typing in the future. vehicle_final &lt;- vehicle_data %&gt;% filter(year(creation_date) == 2016, month(creation_date) == 9) %&gt;% select(comm = community_area, lon = longitude, lat = latitude) Great, now that I’ve narrowed down my dataset, I can convert it into a spatial format accepted by R! (Note: it’s quite normal to need to clean and prepare your data before using it for spatial analysis. That’s a big part of the data analysis workflow.) 12.6 Spatial data time - my favorite part! The workhouse of the modern R spatial toolkit is the sf package. I love it a lot. To convert a table/CSV with latitude and longitude into an sf format, we use the st_as_sf() function, which has a few arguments. vehicle_points &lt;- st_as_sf(vehicle_final, coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = 4326, agr = &quot;constant&quot;) Uh oh, what happened? I got the following error: Error in st_as_sf.data.frame(vehicle_final, coords = c(&quot;lon&quot;, &quot;lat&quot;), : missing values in coordinates not allowed. Challenge I can’t have missing values in my longitude or latitude values! Can you write a filter() statement with the is.na() function to remove the missing lon and lat points from vehicle_final? Save it to vehicle_coord, and check your work with dim() Let’s try again… vehicle_points &lt;- st_as_sf(vehicle_coord, coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = 4326, agr = &quot;constant&quot;) Challenge Check the class() of your new vehicle_points object. Call the plot() function on it! Also call the st_crs() function on it. 12.7 On your own Challenge Can you work through the tutorial here to import spatial data that’s not in data frame format? Stop once you’ve plotted the areas. 12.8 Very important concepts: projection, and spatial join Two of the most important spatial concepts are projections, and spatial joins (not to be confused with attribute joins). You can read Luc’s notes to understand what’s going on, but here are two graphics to explain what’s going on. The two key functions you need to know are: st_transform() st_join() Good luck with the rest of the tutorial! "],
["basic-mapping.html", "Chapter 13 Basic Mapping 13.1 Outline of Today’s Workshop 13.2 Spatial Data Handling, fin 13.3 Finding Spatial Data 13.4 Basic Mapping", " Chapter 13 Basic Mapping 13.1 Outline of Today’s Workshop We’ll be doing the following few things: finishing up Spatial Data Handling discussing finding open-source geospatial data, then working from this Basic Mapping lab tutorial. 13.2 Spatial Data Handling, fin There’s a long section in the tutorial about PDF scraping. If you’ve already done it, sorry! I just put together a data package that you can install to use with these tutorials. Install the package with: # install.packages(&quot;remotes&quot;) remotes::install_github(&quot;spatialanalysis/geodaData&quot;) Then, you can pull up the community area data with population attached with: library(geodaData) library(sf) data(&quot;chicago_comm&quot;) 13.3 Finding Spatial Data Based on a question from last week, I put together a list with some sources of spatial data. Question What type of spatial data are you interested in using for your research? Please write down the research question and the type of data you are thinking about using here! Question Where do you think you might be able to find that geospatial data? Take 5 minutes to do a search, discuss with a partner, and jot down your ideas here! 13.4 Basic Mapping I’m moving to mapping to make sure we cover the necessary spatial concepts, as some of the exploratory data analysis you may have already encountered. We may go back to the multivariate analysis next week, if time. Question How many people feel comfortable with ggplot already? How many people can run a regression in R? To use the NYC boundary data included in the tutorial, run the following code: library(geodaData) library(sf) nyc_bound &lt;- data(&quot;nyc_sf&quot;) Some resources I find useful for tmap include: the tmap examples the Geocomputation with R site Question Take a few minutes and try to understand what the NYC data is about. How many observations and variables are there? What data is stored? What geometries are included? Question Can you try to replicate one of the map styles in the tmap examples (here’s the code used to create them), using the NYC data we just worked with? Take a few minutes and try it out! "]
]
